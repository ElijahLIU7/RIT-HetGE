{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"Times New Roman\"]\n",
    "\n",
    "# 数据\n",
    "eta = []\n",
    "acc = []\n",
    "pre = []\n",
    "rec = []\n",
    "f1 = []\n",
    "auc = []\n",
    "\n",
    "plt.figure(figsize=(8, 7), dpi=300)\n",
    "\n",
    "plt.plot(eta, acc, marker='o', markersize=8, color='#FF4500', linewidth=3.5, label='ACC')\n",
    "plt.plot(eta, f1, marker='d', markersize=8, color='#1E90FF', linewidth=3.5, label='F1')\n",
    "\n",
    "plt.plot(eta, pre, marker='s', markersize=6, color='#32CD32', linewidth=2, alpha=0.7, label='PRE')\n",
    "plt.plot(eta, rec, marker='^', markersize=6, color='#9370DB', linewidth=2, alpha=0.7, label='REC')\n",
    "plt.plot(eta, auc, marker='*', markersize=10, color='#FFD700', linewidth=2, alpha=0.7, label='AUC')\n",
    "\n",
    "for x, y in zip(eta, acc):\n",
    "    plt.annotate(f'{y:.2f}', (x, y), textcoords='offset points',\n",
    "                 xytext=(0, 8), ha='center', fontsize=10)\n",
    "\n",
    "for x, y in zip(eta, f1):\n",
    "    plt.annotate(f'{y:.2f}', (x, y), textcoords='offset points',\n",
    "                 xytext=(0, -12), ha='center', fontsize=10)\n",
    "\n",
    "plt.title('The classification task', fontsize=18)\n",
    "plt.xlabel('$\\eta_1$', fontsize=16)\n",
    "plt.ylabel('Value(%)', fontsize=16)\n",
    "plt.xticks(eta)\n",
    "plt.yticks(np.arange(40, 105, 5))  # 更精细的纵坐标刻度\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=12, framealpha=1)\n",
    "\n",
    "best_acc_idx = acc.index(max(acc))\n",
    "best_f1_idx = f1.index(max(f1))\n",
    "plt.scatter([eta[best_acc_idx]], [max(acc)], color='red', s=100, zorder=5)\n",
    "plt.scatter([eta[best_f1_idx]], [max(f1)], color='blue', s=100, zorder=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('classification_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "6429d5869f062eee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"Times New Roman\"]\n",
    "\n",
    "# 回归数据数据\n",
    "rho = []\n",
    "mse = []\n",
    "mae = []\n",
    "r2 = []\n",
    "pcc = []\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 7), dpi=300)\n",
    "\n",
    "ax1.plot(rho, mse, marker='o', markersize=8, color='#0066CC', linewidth=3.5, label='MSE')\n",
    "ax1.plot(rho, mae, marker='s', markersize=6, color='#66B3FF', linewidth=2, alpha=0.7, label='MAE')\n",
    "ax1.set_ylabel('The values of MSE and MAE', fontsize=14)\n",
    "ax1.tick_params(axis='y', labelcolor=\"#0000FF\")\n",
    "ax1.set_ylim(bottom=3, top=8.5)\n",
    "\n",
    "for x, y in zip(rho, mse):\n",
    "    plt.annotate(f'{y:.2f}', (x, y), textcoords='offset points',\n",
    "                 xytext=(0, -12), ha='center', fontsize=10)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(rho, r2, marker='^', markersize=6, color='#008000', linewidth=2, alpha=0.7, label='$R^2$')\n",
    "ax2.plot(rho, pcc, marker='d', markersize=8, color='#80CC80', linewidth=3.5, label='PCC')\n",
    "ax2.set_ylabel('The values of PCC and $R^2$', fontsize=14)\n",
    "ax2.tick_params(axis='y', labelcolor=\"#00FF00\")\n",
    "ax2.set_ylim(bottom=0.35, top=0.9)\n",
    "\n",
    "for x, y in zip(rho, pcc):\n",
    "    plt.annotate(f'{y:.2f}', (x, y), textcoords='offset points',\n",
    "                 xytext=(0, 8), ha='center', fontsize=10)\n",
    "\n",
    "plt.title('The regression task', fontsize=18)\n",
    "ax1.set_xlabel('$\\\\rho_2$', fontsize=16)\n",
    "plt.xticks(rho, fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "plt.legend(lines1 + lines2, labels1 + labels2,\n",
    "           loc='lower right', fontsize=12, framealpha=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('regression_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "e96d58ef6fb7454a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==================== Data input and organization ====================\n",
    "data = {}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ==================== Calculate the differences and statistics ====================\n",
    "models = df.columns[1:]\n",
    "n_models = len(models)\n",
    "mean_diff = []\n",
    "ci_lower = []\n",
    "ci_upper = []\n",
    "p_values = []\n",
    "\n",
    "for model in models:\n",
    "    diff = df[\"ours\"] - df[model]\n",
    "    t_stat, p_val = stats.ttest_rel(df[\"ours\"], df[model])\n",
    "    md = diff.mean()\n",
    "    se = diff.std() / np.sqrt(len(diff))\n",
    "    ci = stats.t.interval(0.95, len(diff)-1, loc=md, scale=se)\n",
    "    mean_diff.append(md)\n",
    "    ci_lower.append(ci[0])\n",
    "    ci_upper.append(ci[1])\n",
    "    p_values.append(p_val)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"model\": models,\n",
    "    \"mean_diff\": mean_diff,\n",
    "    \"ci_lower\": ci_lower,\n",
    "    \"ci_upper\": ci_upper,\n",
    "    \"p_value\": p_values\n",
    "})\n",
    "\n",
    "# ==================== Draw a vertical forest map ====================\n",
    "plt.figure(figsize=(8, 10), dpi=300)\n",
    "sns.set_style(\"whitegrid\", {\"grid.linestyle\": \"--\"})\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "\n",
    "x_pos = np.arange(n_models)\n",
    "\n",
    "plt.errorbar(\n",
    "    x=x_pos,\n",
    "    y=results_df[\"mean_diff\"],\n",
    "    yerr=np.vstack((results_df[\"mean_diff\"] - results_df[\"ci_lower\"],  # 下限差\n",
    "                    results_df[\"ci_upper\"] - results_df[\"mean_diff\"])),  # 上限差\n",
    "    fmt=\"o\",\n",
    "    ecolor=\"#2c7fb8\",\n",
    "    color=\"#668B8B\",\n",
    "    ms=8,\n",
    "    capsize=5,\n",
    "    lw=1.5,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "plt.axhline(y=0, color=\"red\", linestyle=\"--\", linewidth=1.2, zorder=0)\n",
    "\n",
    "for i, row in results_df.iterrows():\n",
    "    plt.text(x_pos[i], -0.25, row[\"model\"], ha=\"center\", va=\"top\",\n",
    "             rotation=45, fontweight=\"bold\", fontsize=12)\n",
    "\n",
    "    sig = \"*\" * sum([row[\"p_value\"] < 0.001, row[\"p_value\"] < 0.01, row[\"p_value\"] < 0.05])\n",
    "    plt.text(x_pos[i], row[\"ci_upper\"] + 0.2,\n",
    "             f\"Δ={row['mean_diff']:.2f}% \\n(p={row['p_value']:.4f}{sig})\",\n",
    "             ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "models = df.columns[1:]\n",
    "\n",
    "plt.ylabel(\"Performance Difference (ours - Baseline) [Accuracy %]\", fontsize=14)\n",
    "plt.xticks(x_pos, [])\n",
    "plt.ylim(0, max(results_df[\"ci_upper\"]) + 2)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fa7efe8cafb491fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# ==================== Data input and organization ====================\n",
    "data = {}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ==================== Calculate the differences and statistics ====================\n",
    "models = df.columns[1:]\n",
    "n_models = len(models)\n",
    "mean_diff = []\n",
    "ci_lower = []\n",
    "ci_upper = []\n",
    "p_values = []\n",
    "hr_values = []\n",
    "hr_lower = []\n",
    "hr_upper = []\n",
    "\n",
    "def create_survival_data(our_data, model_data):\n",
    "    event_times = np.concatenate([our_data, model_data])\n",
    "    events = np.concatenate([np.ones_like(our_data), np.zeros_like(model_data)])\n",
    "    groups = np.concatenate([np.ones_like(our_data), np.zeros_like(model_data)])\n",
    "\n",
    "    survival_df = pd.DataFrame({\n",
    "        'time': event_times,\n",
    "        'event': events,\n",
    "        'group': groups\n",
    "    })\n",
    "\n",
    "    return survival_df\n",
    "\n",
    "for model in models:\n",
    "    diff = df[\"ours\"] - df[model]\n",
    "    t_stat, p_val = stats.ttest_rel(df[\"ours\"], df[model])\n",
    "    md = diff.mean()\n",
    "    se = diff.std() / np.sqrt(len(diff))\n",
    "    ci = stats.t.interval(0.95, len(diff)-1, loc=md, scale=se)\n",
    "\n",
    "    survival_data = create_survival_data(df[\"ours\"], df[model])\n",
    "\n",
    "    results = logrank_test(\n",
    "        survival_data[survival_data['group'] == 1]['time'],\n",
    "        survival_data[survival_data['group'] == 0]['time'],\n",
    "        event_observed_A=survival_data[survival_data['group'] == 1]['event'],\n",
    "        event_observed_B=survival_data[survival_data['group'] == 0]['event']\n",
    "    )\n",
    "\n",
    "    hr = np.exp(results.test_statistic / (len(df) * 2))\n",
    "\n",
    "    z = 1.96\n",
    "    se_log_hr = np.sqrt(1/sum(survival_data['event'] == 1) + 1/sum(survival_data['event'] == 0))\n",
    "    hr_ci_lower = np.exp(np.log(hr) - z * se_log_hr)\n",
    "    hr_ci_upper = np.exp(np.log(hr) + z * se_log_hr)\n",
    "\n",
    "    mean_diff.append(md)\n",
    "    ci_lower.append(ci[0])\n",
    "    ci_upper.append(ci[1])\n",
    "    p_values.append(p_val)\n",
    "    hr_values.append(hr)\n",
    "    hr_lower.append(hr_ci_lower)\n",
    "    hr_upper.append(hr_ci_upper)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Mean Difference (%)\": mean_diff,\n",
    "    \"95% CI Lower (%)\": ci_lower,\n",
    "    \"95% CI Upper (%)\": ci_upper,\n",
    "    \"P-value\": p_values,\n",
    "    \"Hazard Ratio\": hr_values,\n",
    "    \"95% HR Lower\": hr_lower,\n",
    "    \"95% HR Upper\": hr_upper\n",
    "})\n",
    "\n",
    "results_df.to_excel(\"model_comparison_results.xlsx\", index=False)\n",
    "print(\"The result has been successfully output to 'model_comparison_results.xlsx'\")"
   ],
   "id": "26724657dda55d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==================== Data input and organization ====================\n",
    "data = {}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ==================== Calculate the differences and statistics ====================\n",
    "models = df.columns[1:]\n",
    "n_models = len(models)\n",
    "mean_diff = []\n",
    "ci_lower = []\n",
    "ci_upper = []\n",
    "p_values = []\n",
    "\n",
    "for model in models:\n",
    "    diff = df[\"ours\"] - df[model]\n",
    "    t_stat, p_val = stats.ttest_rel(df[\"ours\"], df[model])\n",
    "    md = diff.mean()\n",
    "    se = diff.std() / np.sqrt(len(diff))\n",
    "    ci = stats.t.interval(0.95, len(diff)-1, loc=md, scale=se)\n",
    "    mean_diff.append(md)\n",
    "    ci_lower.append(ci[0])\n",
    "    ci_upper.append(ci[1])\n",
    "    p_values.append(p_val)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"model\": models,\n",
    "    \"mean_diff\": mean_diff,\n",
    "    \"ci_lower\": ci_lower,\n",
    "    \"ci_upper\": ci_upper,\n",
    "    \"p_value\": p_values\n",
    "})\n",
    "\n",
    "# ==================== Draw a vertical forest map ====================\n",
    "plt.figure(figsize=(8, 10), dpi=300)\n",
    "sns.set_style(\"whitegrid\", {\"grid.linestyle\": \"--\"})\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "\n",
    "x_pos = np.arange(n_models)\n",
    "\n",
    "plt.errorbar(\n",
    "    x=x_pos,\n",
    "    y=results_df[\"mean_diff\"],\n",
    "    yerr=[results_df[\"mean_diff\"] - results_df[\"ci_lower\"],\n",
    "          results_df[\"ci_upper\"] - results_df[\"mean_diff\"]],\n",
    "    fmt=\"*\",\n",
    "    ecolor=\"#2c7fb8\",\n",
    "    color=\"#DAA520\",\n",
    "    ms=10,\n",
    "    capsize=6,\n",
    "    lw=1.5,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "plt.axhline(y=0, color=\"red\", linestyle=\"--\", linewidth=1.2, zorder=0)\n",
    "\n",
    "for i, row in results_df.iterrows():\n",
    "    plt.text(x_pos[i], -0.012, row[\"model\"],\n",
    "             ha=\"center\", va=\"top\",\n",
    "             rotation=45,\n",
    "             fontweight=\"bold\",\n",
    "             fontsize=12)\n",
    "\n",
    "    sig = \"*\" * sum([row[\"p_value\"] < 0.001, row[\"p_value\"] < 0.01, row[\"p_value\"] < 0.05])\n",
    "    plt.text(x_pos[i], row[\"ci_upper\"] + 0.01,\n",
    "             f\"Δ={row['mean_diff']:.2f}\\n(p={row['p_value']:.4f}{sig})\",\n",
    "             ha=\"center\", va=\"bottom\",\n",
    "             fontsize=10)\n",
    "\n",
    "plt.ylabel(\"Performance Difference (ours - Baseline) [PCC]\", fontsize=14)\n",
    "plt.xticks(x_pos, [])\n",
    "plt.ylim(0, max(results_df[\"ci_upper\"]) + 0.1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5c16b134eefe41ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def count_residues(file_pattern, reference_residues=None):\n",
    "    residue_counter_high = defaultdict(int)\n",
    "    residue_counter_low = defaultdict(int)\n",
    "\n",
    "    for filename in glob.glob(file_pattern):\n",
    "        try:\n",
    "            tm_match = re.search(r'Tm-([0-9\\.]+)', filename)\n",
    "            tm_value = float(tm_match.group(1)[:-1])\n",
    "            with open(filename, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                next(reader)\n",
    "                for row in reader:\n",
    "                    if len(row) < 2:\n",
    "                        continue\n",
    "                    residue = row[1].strip().capitalize()\n",
    "                    if residue:\n",
    "                        if tm_value >= 60:\n",
    "                            residue_counter_high[residue] += 1\n",
    "                        else:\n",
    "                            residue_counter_low[residue] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {str(e)}\")\n",
    "\n",
    "    if reference_residues:\n",
    "        sorted_residues = reference_residues\n",
    "    else:\n",
    "        sorted_residues = sorted(residue_counter_high.keys(),\n",
    "                               key=lambda x: residue_counter_high[x], reverse=True)\n",
    "\n",
    "    return (\n",
    "        {k: residue_counter_high.get(k, 0) for k in sorted_residues},\n",
    "        {k: residue_counter_low.get(k, 0) for k in sorted_residues}\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    reg_file_pattern = './results/HRIN-ProTstab/regression/Test_Graph_top_k/*nodes_relations*.csv'\n",
    "    reg_high, reg_low = count_residues(reg_file_pattern)\n",
    "    sorted_residues = list(reg_high.keys())\n",
    "\n",
    "    class_file_pattern = './results/HRIN-ProTstab/classification/Test_Graph_top_k/*nodes_relations*.csv'\n",
    "    class_high, class_low = count_residues(class_file_pattern, reference_residues=sorted_residues)\n",
    "\n",
    "    def get_percentage(data_dict, total):\n",
    "        return {k: (v / total * 100) if total != 0 else 0 for k, v in data_dict.items()}\n",
    "\n",
    "    total_reg_high = sum(reg_high.values())\n",
    "    total_reg_low = sum(reg_low.values())\n",
    "    total_class_high = sum(class_high.values())\n",
    "    total_class_low = sum(class_low.values())\n",
    "\n",
    "    reg_high_pct = get_percentage(reg_high, total_reg_high)\n",
    "    reg_low_pct = get_percentage(reg_low, total_reg_low)\n",
    "    class_high_pct = get_percentage(class_high, total_class_high)\n",
    "    class_low_pct = get_percentage(class_low, total_class_low)\n",
    "\n",
    "    # 准备绘图数据（按排序后的残基顺序）\n",
    "    residues = sorted_residues\n",
    "    data = [\n",
    "        [reg_high_pct[r] for r in residues],\n",
    "        [reg_low_pct[r] for r in residues],\n",
    "        [class_high_pct[r] for r in residues],\n",
    "        [class_low_pct[r] for r in residues]\n",
    "    ]\n",
    "\n",
    "    # 绘图参数\n",
    "    fig, ax = plt.subplots(figsize=(16, 9), dpi=300)\n",
    "    bar_width = 0.18\n",
    "    group_space = 0.3\n",
    "    index = range(len(residues))\n",
    "\n",
    "    colors = ['#FF4444', '#FF9933', '#3366CC', '#66CCEE']\n",
    "    labels = [\n",
    "        'Regression (Tm≥60°C)',\n",
    "        'Regression (Tm<60°C)',\n",
    "        'Classification (Tm≥60°C)',\n",
    "        'Classification (Tm<60°C)'\n",
    "    ]\n",
    "\n",
    "    for i in range(4):\n",
    "        x_pos = [j * (bar_width*4 + group_space) + i*bar_width for j in index]\n",
    "        ax.bar(x_pos, data[i], bar_width, color=colors[i], edgecolor='black', label=labels[i])\n",
    "\n",
    "    ax.set_xlabel('Residue Type', fontsize=16)\n",
    "    ax.set_ylabel('Percentage (%)', fontsize=16)\n",
    "\n",
    "    ax.set_xticks([j*(bar_width*4 + group_space) + bar_width*1.5 for j in index])\n",
    "    ax.set_xticklabels(residues, rotation=45, ha='center', fontsize=15)\n",
    "\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7, zorder=0)\n",
    "    ax.legend(loc='upper right', fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('combined_task_residue_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 统计输出\n",
    "    print(\"\\n===== Task Statistics Summary =====\")\n",
    "    print(\"Regression problem task：\")\n",
    "    print(f\"Residue types at Tm≥60°C: {len(reg_high)}, Residue types at Tm<60°C: {len(reg_low)}\")\n",
    "    print(\"分类任务：\")\n",
    "    print(f\"Residue types at Tm ≥ 60°C: {len(class_high)}, Residue types at Tm < 60°C: {len(class_low)}\")\n",
    "    print(\"\\n===== Details of the proportion of all residues =====\")\n",
    "    header = f\"{'Residues':<8} | {'Regression (Tm≥60%)':>12} | {'Regression (Tm<60%)':>12} | {'Classification (Tm≥60%)':>12} | {'Classification (Tm<60%)':>12}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for residue in residues:\n",
    "        rh = reg_high_pct[residue]\n",
    "        rl = reg_low_pct[residue]\n",
    "        ch = class_high_pct[residue]\n",
    "        cl = class_low_pct[residue]\n",
    "        row = f\"{residue:<8} | {rh:>12.2f}% | {rl:>12.2f}% | {ch:>12.2f}% | {cl:>12.2f}%\"\n",
    "        print(row)"
   ],
   "id": "f1763c809d5589e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_residue_name(name):\n",
    "    if not name:\n",
    "        return name\n",
    "    return name[0].upper() + name[1:].lower()\n",
    "\n",
    "def calculate_residue_percentage(residue_counts):\n",
    "    total = sum(residue_counts.values())\n",
    "    return {res: (count/total)*100 for res, count in residue_counts.items()}\n",
    "\n",
    "\n",
    "def extract_interaction_scores(file_pattern):\n",
    "    interaction_scores = defaultdict(lambda: defaultdict(float))\n",
    "    interaction_counts = defaultdict(lambda: defaultdict(int))\n",
    "    residue_totals = defaultdict(float)  # 存储每个残基的总作用力分数\n",
    "    residue_counts = defaultdict(int)\n",
    "    interactions = ['VDW', 'PIPISTACK', 'HBOND', 'IONIC', 'SSBOND', 'PICATION']\n",
    "\n",
    "    for filename in glob.glob(file_pattern):\n",
    "        try:\n",
    "            tm_match = re.search(r'Tm-([0-9\\.]+)', filename)\n",
    "            if not tm_match:\n",
    "                continue\n",
    "\n",
    "            with open(filename, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                next(reader)\n",
    "                for row in reader:\n",
    "                    if len(row) < 2:\n",
    "                        continue\n",
    "                    residue = row[1].strip().upper()\n",
    "                    residue_counts[residue] += 1\n",
    "                    if residue:\n",
    "                        for count, i in enumerate(interactions):\n",
    "                            protein = re.search(r'graph_([^_]+)_nodes', filename)\n",
    "                            path = f\"../data/HRIN-ProTstab/HNet/test/{i}/{protein.group(1)}.csv\"\n",
    "                            with open(path, 'r') as g:\n",
    "                                reader_1 = csv.reader(g)\n",
    "                                for row_1 in reader_1:\n",
    "                                    if str(int(row_1[0][2:-6])) == row[0] or str(int(row_1[2][2:-6])) == row[0]:\n",
    "                                        interaction_scores[residue][i] += float(row[count+2])\n",
    "                                        interaction_counts[residue][i] += 1\n",
    "\n",
    "            residue_percent = calculate_residue_percentage(residue_counts)\n",
    "        except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {str(e)}\")\n",
    "\n",
    "    return interaction_scores, interaction_counts, residue_percent\n",
    "\n",
    "\n",
    "def calculate_normalized_scores(interaction_scores, interaction_counts):\n",
    "    residue_specific_scores = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    for residue in interaction_scores:\n",
    "        total = interaction_counts[residue]\n",
    "        if total > 0:\n",
    "            for interaction in interaction_scores[residue]:\n",
    "                residue_specific_scores[residue][interaction] = (\n",
    "                        interaction_scores[residue][interaction] / total * 100\n",
    "                )\n",
    "\n",
    "    return residue_specific_scores\n",
    "\n",
    "\n",
    "def plot_interaction_heatmap(residue_specific_scores):\n",
    "    if not residue_specific_scores:\n",
    "        print(\"There is no available data to draw the heat map.\")\n",
    "        return\n",
    "\n",
    "    residues = sorted(residue_specific_scores.keys())\n",
    "    interactions = ['VDW', 'PIPISTACK', 'HBOND', 'IONIC', 'SSBOND', 'PICATION']\n",
    "\n",
    "    formatted_residues = [clean_residue_name(res) for res in residues]\n",
    "\n",
    "    scores_matrix = np.array(\n",
    "        [[residue_specific_scores[residue][interaction] for interaction in interactions]\n",
    "         for residue in residues]\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 8), dpi=300)\n",
    "    sns.heatmap(\n",
    "        scores_matrix,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"YlGnBu\",\n",
    "        xticklabels=interactions,\n",
    "        yticklabels=formatted_residues,\n",
    "        cbar_kws={'label': 'Percentage of Residue Total (%)'}\n",
    "    )\n",
    "    plt.xlabel(\"Interaction Types\", fontsize=14)\n",
    "    plt.ylabel(\"Residue Types\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"residue_specific_interaction_heatmap.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_to_csv(df, filename=\"residue_interaction_distribution.csv\"):\n",
    "    df.to_csv(filename, index=False, float_format=\"%.2f\")\n",
    "    print(f\"The data has been saved to {filename}.\")\n",
    "\n",
    "\n",
    "def save_to_dataframe(residue_specific_scores):\n",
    "    interactions = ['VDW', 'PIPISTACK', 'HBOND', 'IONIC', 'SSBOND', 'PICATION', 'SELF']\n",
    "    residues = sorted(residue_specific_scores.keys())\n",
    "\n",
    "    data = []\n",
    "    for residue in residues:\n",
    "        row = {'Residue': residue}\n",
    "        for interaction in interactions:\n",
    "            row[interaction] = residue_specific_scores[residue].get(interaction, 0)\n",
    "        data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    totals = df[interactions].sum()\n",
    "    totals['Residue'] = 'TOTAL'\n",
    "    df = df.append(totals, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_pattern = \"./results/HRIN-ProTstab/regression/Test_Graph_top_k/*nodes_relations*.csv\"  # 文件路径\n",
    "    interaction_scores, interaction_counts, residue_percent = extract_interaction_scores(file_pattern)\n",
    "\n",
    "    print(\"\\nStatistics on the proportion of residues:\")\n",
    "    for res, percent in sorted(residue_percent.items()):\n",
    "        print(f\"{res}: {percent:.2f}%\")\n",
    "\n",
    "    residue_specific_scores = calculate_normalized_scores(interaction_scores, interaction_counts)\n",
    "\n",
    "    plot_interaction_heatmap(residue_specific_scores)\n",
    "\n",
    "    df = save_to_dataframe(residue_specific_scores)\n",
    "\n",
    "    # 打印表格\n",
    "    print(\"\\nDistribution Table of residue Interaction Forces (Percentage):\")\n",
    "    print(df.to_string(index=False, float_format=\"%.2f\"))\n"
   ],
   "id": "559318101e38b050",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "residue_percent = {}\n",
    "\n",
    "interaction_data = {}\n",
    "\n",
    "df_node = pd.DataFrame.from_dict(residue_percent, orient='index', columns=['Abundance (%)'])\n",
    "df_node = df_node.sort_values(by='Abundance (%)', ascending=False)\n",
    "\n",
    "df_edge = pd.DataFrame(interaction_data).set_index('Residue')\n",
    "interactions = ['VDW', 'PIPISTACK', 'HBOND', 'IONIC', 'SSBOND', 'PICATION', 'SELF']\n",
    "df_edge = df_edge[interactions]\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(\n",
    "    x=df_node.index,\n",
    "    y=df_node['Abundance (%)'],\n",
    "    palette='viridis',\n",
    "    edgecolor='black'\n",
    ")\n",
    "plt.title('(a) Key Residue Abundance in Thermostable Proteins', fontsize=14)\n",
    "plt.xlabel('Residue Type', fontsize=12)\n",
    "plt.ylabel('Abundance Percentage (%)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "for p in plt.gca().patches:\n",
    "    height = p.get_height()\n",
    "    plt.text(p.get_x() + p.get_width()/2., height,\n",
    "            f'{height:.1f}%',\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(\n",
    "    df_edge,\n",
    "    annot=True,\n",
    "    fmt='.1f',\n",
    "    cmap='YlGnBu',\n",
    "    cbar_kws={'label': 'Interaction Percentage (%)'}\n",
    ")\n",
    "plt.title('(b) Residue-Interaction Strength Distribution', fontsize=14)\n",
    "plt.xlabel('Interaction Types', fontsize=12)\n",
    "plt.ylabel('Residue Type', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.text(1, 8, '*The accumulation effect of Phe is significant', fontsize=10, color='red', ha='center')\n",
    "plt.text(2, 0, '*His is dominated by hydrogen bond', fontsize=10, color='red', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('node_edge_correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "59fda37f48175cd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def calculate_normalized_scores():\n",
    "    data = \"\"\"\"\"\"\n",
    "    lines = [line.strip() for line in data.split('\\n') if line.strip()]\n",
    "    header = lines[0].split('\\t')\n",
    "    residues = [line.split('\\t')[0] for line in lines[1:]]\n",
    "    interactions = header[1:]\n",
    "\n",
    "    residue_specific_scores = defaultdict(lambda: defaultdict(float))\n",
    "    for line in lines[1:]:\n",
    "        parts = line.split('\\t')\n",
    "        residue = parts[0]\n",
    "        for i, interaction in enumerate(interactions):\n",
    "            score = float(parts[i+1])\n",
    "            residue_specific_scores[residue][interaction] = score * 100  # 转换为百分比\n",
    "\n",
    "    return residue_specific_scores, residues, interactions\n",
    "\n",
    "def plot_interaction_heatmap(residue_specific_scores, residues, interactions):\n",
    "    if not residue_specific_scores:\n",
    "        print(\"There is no available data to generate a heat map.\")\n",
    "        return\n",
    "\n",
    "    scores_matrix = np.array([\n",
    "        [residue_specific_scores[residue][interaction] for interaction in interactions]\n",
    "        for residue in residues\n",
    "    ])\n",
    "\n",
    "    plt.figure(figsize=(12, 8), dpi=300)\n",
    "    sns.heatmap(\n",
    "        scores_matrix,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"YlGnBu\",\n",
    "        xticklabels=interactions,\n",
    "        yticklabels=residues,\n",
    "        cbar_kws={'label': 'Proportion of residue interactions (%)'}\n",
    "    )\n",
    "    plt.xlabel(\"Interaction Types\", fontsize=16)\n",
    "    plt.ylabel(\"Residue Types\", fontsize=16)\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=12)\n",
    "    plt.yticks(rotation=0, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"residue_interaction_heatmap.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    residue_specific_scores, residues, interactions = calculate_normalized_scores()\n",
    "\n",
    "    print(\"Residue-interaction ratio table:\")\n",
    "    for residue in residues:\n",
    "        print(f\"{residue}: {', '.join([f'{interaction}={residue_specific_scores[residue][interaction]:.2f}%' for interaction in interactions])}\")\n",
    "\n",
    "    plot_interaction_heatmap(residue_specific_scores, residues, interactions)\n"
   ],
   "id": "1aa808a818f98170",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
